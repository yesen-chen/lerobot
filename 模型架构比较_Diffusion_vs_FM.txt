================================================================================
              Diffusion Policy (DDPM) vs Flow Matching (FM) 比较
================================================================================

说明: 
  - Diffusion = LeRobot modeling_diffusion.py (Diffusion Policy, DDPM/DDIM)
  - FM = ILStudio Flow Matching (modeling.py)
  "dp" 若指 Diffusion Policy，则 modeling_diffusion.py 即为 DP 实现

================================================================================
一、Diffusion Policy 架构 (modeling_diffusion.py)
================================================================================
论文: "Diffusion Policy: Visuomotor Policy Learning via Action Diffusion"
基于: DDPM 正向/逆向扩散过程

┌─────────────────────────────────────────────────────────────────────────────┐
│                         DiffusionPolicy / DiffusionModel                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  输入: state + images [B, n_obs_steps, ...]  (多步观测)                       │
│        输出: action chunk [B, horizon, action_dim]                            │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ _prepare_global_conditioning                                           │   │
│  │   state ──────────────────────┐                                      │   │
│  │   images ──► ResNet backbone ──► SpatialSoftmax ──► img_feat ──┤      │   │
│  │   env_state ──────────────────┐                                      │   │
│  │   global_cond = concat(...).flatten()  [B, global_cond_dim]           │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│           │                                                                  │
│           ▼                                                                  │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ 训练: 前向扩散 (Forward Diffusion)                                    │   │
│  │                                                                       │   │
│  │   trajectory = batch[ACTION]  [B, horizon, action_dim]                │   │
│  │   eps ~ N(0, I)                                                       │   │
│  │   t ~ Uniform(0, T-1)  离散步 [0, 99] 默认                            │   │
│  │   x_t = sqrt(α̅_t)·trajectory + sqrt(1-α̅_t)·eps   (噪声调度)            │   │
│  │                                                                       │   │
│  │   pred = Unet(x_t, t, global_cond)                                    │   │
│  │   target = eps (epsilon) 或 trajectory (sample)                       │   │
│  │   Loss = MSE(pred, target)                                            │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ 推理: 逆向采样 (DDPM/DDIM scheduler)                                   │   │
│  │                                                                       │   │
│  │   x_T ~ N(0, I)                                                       │   │
│  │   for t in [T-1, T-2, ..., 0]:                                        │   │
│  │       pred = Unet(x_t, t, global_cond)                                │   │
│  │       x_{t-1} = scheduler.step(pred, t, x_t)  (调度器公式)             │   │
│  │   return x_0  (denoised trajectory)                                  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                    DiffusionConditionalUnet1d                                │
│  - 1D 卷积 UNet (在时间维度 horizon 上卷积)                                   │
│  - timestep t 编码 → SinusoidalPosEmb → MLP → diffusion_step_embed           │
│  - cond = concat(timestep_embed, global_cond) → FiLM 调制                     │
│  - 预测: epsilon (噪声) 或 sample (直接预测 x_0)                              │
└─────────────────────────────────────────────────────────────────────────────┘


================================================================================
二、Flow Matching 架构 (ILStudio modeling.py)
================================================================================
基于: Conditional Flow Matching (Lipman et al., 2023)

┌─────────────────────────────────────────────────────────────────────────────┐
│                         FlowMatchingPolicy                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  输入: state [B, state_dim]   (无图像，纯状态)                                │
│        输出: action [B, chunk_size, action_dim]                              │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ 训练: Flow Matching Loss                                              │   │
│  │                                                                       │   │
│  │   t ~ Uniform(ε, 1)  连续时间                                         │   │
│  │   noise ~ N(0, I)                                                     │   │
│  │   a_t = t·action + (1-t)·noise   线性插值                             │   │
│  │   u_t = action - noise           目标速度 (常数)                     │   │
│  │                                                                       │   │
│  │   v_pred = VelocityModel(a_t, t, state)                                │   │
│  │   Loss = MSE(v_pred, u_t)                                             │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ 推理: ODE 积分 / Euler 步进                                           │   │
│  │                                                                       │   │
│  │   a_0 ~ N(0, I)                                                       │   │
│  │   da/dt = v_θ(a_t, t, state)                                          │   │
│  │   t: 0 → 1 积分 (ODE dopri5 或 Euler)                                 │   │
│  │   return a_1  (最终动作)                                               │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘


================================================================================
三、核心差异: 拟合目标与数学形式
================================================================================

┌──────────────────────┬─────────────────────────────┬─────────────────────────────┐
│       项目           │  Diffusion (DDPM)            │  Flow Matching              │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 时间表示             │ 离散步 t ∈ {0,1,...,T-1}     │ 连续 t ∈ [0, 1]              │
│                      │ (如 T=100)                   │                              │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 加噪方式             │ x_t = √α̅_t·x_0 + √(1-α̅_t)·ε  │ a_t = t·x_1 + (1-t)·x_0      │
│                      │ (方差调度 β_t 决定 α_t)       │ (线性插值，无方差调度)        │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 模型预测目标         │ ε (噪声) 或 x_0 (样本)       │ v = x_1 - x_0 (速度场)       │
│                      │ 通过 scheduler 反推 x_{t-1}  │ 直接用于 ODE 积分            │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 训练 loss            │ MSE(pred_ε, ε) 或            │ MSE(v_pred, u_t)             │
│                      │ MSE(pred_x0, x_0)            │ u_t = action - noise         │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 采样方式             │ 迭代: x_t → x_{t-1}          │ 积分: da/dt = v, t: 0→1      │
│                      │ 依赖 scheduler 解析公式      │ ODE solver 或 Euler          │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 数学框架             │ SDE/Score-based              │ ODE/Flow Matching            │
└──────────────────────┴─────────────────────────────┴─────────────────────────────┘


================================================================================
四、网络结构与 conditioning 对比
================================================================================

┌──────────────────────┬─────────────────────────────┬─────────────────────────────┐
│       项目           │  Diffusion Policy            │  Flow Matching              │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 去噪/速度网络        │ 1D-UNet (Conv1d)             │ MLP                         │
│                      │ 在 horizon 维做卷积          │ 单步 MLP                    │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 输入序列             │ [B, horizon, action_dim]     │ [B, action_dim]              │
│                      │ 整段 trajectory              │ 单步 action                  │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 条件注入             │ global_cond + FiLM          │ concat(state)                │
│                      │ (state + image features)     │                             │
├──────────────────────┼─────────────────────────────┼─────────────────────────────┤
│ 观测模态             │ 图像 + state + env_state     │ 仅 state                     │
└──────────────────────┴─────────────────────────────┴─────────────────────────────┘


================================================================================
五、训练流程对比 (需要拟合什么)
================================================================================

【Diffusion】
  每个 batch:
    1. 采样 t ~ [0, T-1]
    2. 采样 ε ~ N(0,I)
    3. x_t = √α̅_t · action + √(1-α̅_t) · ε
    4. pred = Unet(x_t, t, cond)
    5. target = ε (或 action，取决于 prediction_type)
    6. Loss = MSE(pred, target)

  拟合: 在任意噪声水平 t 下，预测噪声 ε 或干净样本 x_0

【Flow Matching】
  每个 batch:
    1. 采样 t ~ U(ε, 1)
    2. 采样 noise ~ N(0,I)
    3. a_t = t·action + (1-t)·noise
    4. u_t = action - noise
    5. v_pred = VelocityModel(a_t, t, state)
    6. Loss = MSE(v_pred, u_t)

  拟合: 在插值路径上任意点 (a_t, t)，预测指向目标的速度向量


================================================================================
六、总结
================================================================================

• Diffusion: 离散步、方差调度、预测噪声/样本，采样依赖 scheduler 迭代
• FM:       连续时间、线性插值、预测速度场，采样用 ODE 积分

两者都是 "噪声 → 动作" 的生成模型，但 Diffusion 基于 score-based/DDPM，
FM 基于 flow-based ODE，数学形式不同，FM 通常采样更少步可达相近效果。
